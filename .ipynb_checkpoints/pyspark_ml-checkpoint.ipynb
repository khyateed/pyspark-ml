{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark for Machine Learning\n",
    "### By Khyatee Desai<br>Nov. 23, 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PySpark using Docker\n",
    "Run the followingDocker command in the terminal to import PySpark for Jupyter Notebooks<br>Source: https://hub.docker.com/r/jupyter/pyspark-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker pull jupyter/pyspark-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker run -it jupyter/pyspark-notebook:latest /bin/bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import PySpark\n",
    "Once PySpark has been installed, import it and instantiate a SparkContext object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify successful installation by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[729, 375, 601, 610, 695]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(range(1000)).count()\n",
    "rdd = sc.parallelize(range(1000))\n",
    "rdd.takeSample(False, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect available PySpark attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PACKAGE_EXTENSIONS',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_accumulatorServer',\n",
       " '_active_spark_context',\n",
       " '_batchSize',\n",
       " '_callsite',\n",
       " '_checkpointFile',\n",
       " '_conf',\n",
       " '_dictToJavaMap',\n",
       " '_do_init',\n",
       " '_encryption_enabled',\n",
       " '_ensure_initialized',\n",
       " '_gateway',\n",
       " '_getJavaStorageLevel',\n",
       " '_initialize_context',\n",
       " '_javaAccumulator',\n",
       " '_jsc',\n",
       " '_jvm',\n",
       " '_lock',\n",
       " '_next_accum_id',\n",
       " '_pickled_broadcast_vars',\n",
       " '_python_includes',\n",
       " '_repr_html_',\n",
       " '_serialize_to_jvm',\n",
       " '_temp_dir',\n",
       " '_unbatched_serializer',\n",
       " 'accumulator',\n",
       " 'addFile',\n",
       " 'addPyFile',\n",
       " 'appName',\n",
       " 'applicationId',\n",
       " 'binaryFiles',\n",
       " 'binaryRecords',\n",
       " 'broadcast',\n",
       " 'cancelAllJobs',\n",
       " 'cancelJobGroup',\n",
       " 'defaultMinPartitions',\n",
       " 'defaultParallelism',\n",
       " 'dump_profiles',\n",
       " 'emptyRDD',\n",
       " 'environment',\n",
       " 'getConf',\n",
       " 'getLocalProperty',\n",
       " 'getOrCreate',\n",
       " 'hadoopFile',\n",
       " 'hadoopRDD',\n",
       " 'master',\n",
       " 'newAPIHadoopFile',\n",
       " 'newAPIHadoopRDD',\n",
       " 'parallelize',\n",
       " 'pickleFile',\n",
       " 'profiler_collector',\n",
       " 'pythonExec',\n",
       " 'pythonVer',\n",
       " 'range',\n",
       " 'runJob',\n",
       " 'sequenceFile',\n",
       " 'serializer',\n",
       " 'setCheckpointDir',\n",
       " 'setJobDescription',\n",
       " 'setJobGroup',\n",
       " 'setLocalProperty',\n",
       " 'setLogLevel',\n",
       " 'setSystemProperty',\n",
       " 'show_profiles',\n",
       " 'sparkHome',\n",
       " 'sparkUser',\n",
       " 'startTime',\n",
       " 'statusTracker',\n",
       " 'stop',\n",
       " 'textFile',\n",
       " 'uiWebUrl',\n",
       " 'union',\n",
       " 'version',\n",
       " 'wholeTextFiles']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the version of Spark and the number of cores being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark Version: 2.4.4\n",
      "Number of Cores Used: 4\n"
     ]
    }
   ],
   "source": [
    "print('PySpark Version:',sc.version)\n",
    "print('Number of Cores Used:',sc.defaultParallelism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminate your SparkContext instance with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import RandomForestClassificationModel, RandomForestClassifier\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoderEstimator\n",
    "\n",
    "# Instantiate Spark Context, and create a Spark Session\n",
    "sc = SparkContext('local[*]')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/datasnaek/chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into a pyspark dataframe\n",
    "df = spark.read.csv('games.csv', header='true', inferSchema='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect  attributes of the spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='TZJHLljE', rated=False, created_at=Decimal('1504210000000'), last_move_at=Decimal('1504210000000'), turns=13, victory_status='outoftime', winner='white', increment_code='15+2', white_id='bourgris', white_rating=1500, black_id='a-00', black_rating=1191, moves='d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5 Bf4', opening_eco='D10', opening_name='Slav Defense: Exchange Variation', opening_ply=5)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'rated',\n",
       " 'created_at',\n",
       " 'last_move_at',\n",
       " 'turns',\n",
       " 'victory_status',\n",
       " 'winner',\n",
       " 'increment_code',\n",
       " 'white_id',\n",
       " 'white_rating',\n",
       " 'black_id',\n",
       " 'black_rating',\n",
       " 'moves',\n",
       " 'opening_eco',\n",
       " 'opening_name',\n",
       " 'opening_ply']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[winner: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('winner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'winner'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('rated', 'boolean'),\n",
       " ('created_at', 'decimal(20,0)'),\n",
       " ('last_move_at', 'decimal(20,0)'),\n",
       " ('turns', 'int'),\n",
       " ('victory_status', 'string'),\n",
       " ('winner', 'string'),\n",
       " ('increment_code', 'string'),\n",
       " ('white_id', 'string'),\n",
       " ('white_rating', 'int'),\n",
       " ('black_id', 'string'),\n",
       " ('black_rating', 'int'),\n",
       " ('moves', 'string'),\n",
       " ('opening_eco', 'string'),\n",
       " ('opening_name', 'string'),\n",
       " ('opening_ply', 'int')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(victory_status='resign'),\n",
       " Row(victory_status='outoftime'),\n",
       " Row(victory_status='mate'),\n",
       " Row(victory_status='draw')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View distinct values\n",
    "df.select('victory_status').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(winner='white'), Row(winner='black'), Row(winner='draw')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('winner').distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='TZJHLljE', rated=False, created_at=Decimal('1504210000000'), last_move_at=Decimal('1504210000000'), turns=13, victory_status='outoftime', winner='white', increment_code='15+2', white_id='bourgris', white_rating=1500, black_id='a-00', black_rating=1191, moves='d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5 Bf4', opening_eco='D10', opening_name='Slav Defense: Exchange Variation', opening_ply=5, duration=Decimal('0'))]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column for game duration\n",
    "df_new = df.withColumn(\"duration\", df['last_move_at'] - df['created_at'])\n",
    "df_new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id='TZJHLljE', rated=False, created_at=Decimal('1504210000000'), last_move_at=Decimal('1504210000000'), turns=13, victory_status='outoftime', winner='white', increment_code='15+2', white_id='bourgris', white_rating=1500, black_id='a-00', black_rating=1191, moves='d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5 Bf4', opening_eco='D10', opening_name='Slav Defense: Exchange Variation', opening_ply=5, duration=Decimal('0'), increment_code_index=21.0, victory_status_index=2.0, opening_name_index=234.0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables for victory_status, increment_code, and opening_name\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df_new) \n",
    "            for column in list(set(['victory_status', 'increment_code','opening_name'])) ]\n",
    "\n",
    "# put all the string indexers in a pipeline, and then just fit&transform the pipeline\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df_r = pipeline.fit(df_new).transform(df_new)\n",
    "\n",
    "df_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id='TZJHLljE', rated=False, created_at=Decimal('1504210000000'), last_move_at=Decimal('1504210000000'), turns=13, victory_status='outoftime', winner='white', increment_code='15+2', white_id='bourgris', white_rating=1500, black_id='a-00', black_rating=1191, moves='d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5 Bf4', opening_eco='D10', opening_name='Slav Defense: Exchange Variation', opening_ply=5, duration=Decimal('0'), increment_code_index=21.0, victory_status_index=2.0, opening_name_index=234.0, victory_status_dummy=SparseVector(3, {2: 1.0}), increment_code_dummy=SparseVector(399, {21: 1.0}), opening_name_dummy=SparseVector(1476, {234: 1.0}))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit and transform the OneHotEncoderEstimator\n",
    "encoder = feature.OneHotEncoderEstimator(inputCols=['victory_status_index', 'increment_code_index', \n",
    "                        'opening_name_index'], outputCols=['victory_status_dummy', \n",
    "                        'increment_code_dummy', 'opening_name_dummy'], dropLast=True)\n",
    "dummy_df = encoder.fit(df_r).transform(df_r)\n",
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id='TZJHLljE', rated=0, created_at=Decimal('1504210000000'), last_move_at=Decimal('1504210000000'), turns=13, victory_status='outoftime', winner=0, increment_code='15+2', white_id='bourgris', white_rating=1500, black_id='a-00', black_rating=1191, moves='d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5 Bf4', opening_eco='D10', opening_name='Slav Defense: Exchange Variation', opening_ply=5, duration=Decimal('0'), increment_code_index=21.0, victory_status_index=2.0, opening_name_index=234.0, victory_status_dummy=SparseVector(3, {2: 1.0}), increment_code_dummy=SparseVector(399, {21: 1.0}), opening_name_dummy=SparseVector(1476, {234: 1.0}))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change boolean values to 0 or 1, and set winner outcome to 0, 1, or 2\n",
    "import pyspark.sql.functions as F\n",
    "dummy_df = dummy_df.withColumn('rated', F.when(df.rated == 'False', 0).otherwise(1))\n",
    "dummy_df = dummy_df.withColumn('winner', F.when(df.winner == 'white', 0).when(df.winner == 'black', 1).otherwise(2))\n",
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rated', 'int'),\n",
       " ('turns', 'int'),\n",
       " ('winner', 'int'),\n",
       " ('white_rating', 'int'),\n",
       " ('black_rating', 'int'),\n",
       " ('opening_ply', 'int'),\n",
       " ('duration', 'decimal(21,0)'),\n",
       " ('victory_status_dummy', 'vector'),\n",
       " ('increment_code_dummy', 'vector'),\n",
       " ('opening_name_dummy', 'vector')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop un-needed columns\n",
    "trimmed_df = dummy_df.drop('id', 'white_id', 'black_id', 'moves', 'last_move_at', 'created_at','opening_eco', 'opening_name', 'opening_name_index',\n",
    "                    'victory_status', 'victory_status_index', 'increment_code', 'increment_code_index')\n",
    "trimmed_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(rated=0, turns=13, winner=0, white_rating=1500, black_rating=1191, opening_ply=5, duration=Decimal('0'), victory_status_dummy=SparseVector(3, {2: 1.0}), increment_code_dummy=SparseVector(399, {21: 1.0}), opening_name_dummy=SparseVector(1476, {234: 1.0}), features=SparseVector(1884, {1: 13.0, 2: 1500.0, 3: 1191.0, 4: 5.0, 8: 1.0, 30: 1.0, 642: 1.0}))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'winner'\n",
    "features = trimmed_df.drop('winner').columns\n",
    "\n",
    "# create a vectorized dataframe using our feature colummns\n",
    "vector = VectorAssembler(inputCols=features, outputCol='features')\n",
    "vector_df = vector.transform(trimmed_df)\n",
    "vector_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "splits = [.75, .25]\n",
    "train_data, test_data = vector_df.randomSplit(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate and fit the model to training data\n",
    "forest_model = RandomForestClassifier(featuresCol='features', labelCol='winner', \n",
    "                            predictionCol='prediction', maxDepth=30, \n",
    "                            impurity='gini', subsamplingRate= .5).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(winner=0, prediction=1.0),\n",
       " Row(winner=0, prediction=0.0),\n",
       " Row(winner=0, prediction=0.0),\n",
       " Row(winner=0, prediction=1.0),\n",
       " Row(winner=1, prediction=1.0),\n",
       " Row(winner=1, prediction=1.0),\n",
       " Row(winner=1, prediction=1.0),\n",
       " Row(winner=1, prediction=0.0),\n",
       " Row(winner=0, prediction=1.0),\n",
       " Row(winner=0, prediction=0.0)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "predictions = forest_model.transform(test_data).select('winner', 'prediction')\n",
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='winner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5598714481554765\n",
      "Accuracy: 0.5901926444833625\n"
     ]
    }
   ],
   "source": [
    "# inspect F1 and accuracy scores\n",
    "print('F1 Score:',evaluator.evaluate(predictions,{evaluator.metricName: 'f1'}))\n",
    "print('Accuracy:',evaluator.evaluate(predictions,{evaluator.metricName: 'accuracy'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.11574097660852146, 'black_rating'),\n",
       " (0.1079818686928678, 'white_rating'),\n",
       " (0.07061671535143461, 'victory_status_dummy'),\n",
       " (0.05389688481245503, 'turns'),\n",
       " (0.04311558176022092, 'increment_code_dummy'),\n",
       " (0.01631043028686818, 'opening_ply'),\n",
       " (0.014358309278006357, 'opening_name_dummy'),\n",
       " (0.014072792937364286, 'duration'),\n",
       " (0.004944454015592373, 'rated')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect feature importance\n",
    "sorted(list(zip(forest_model.featureImportances,features)),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
